
### all search terms
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-07-05**|**Discovering Local Hidden-Variable Models for Arbitrary Multipartite Entangled States and Arbitrary Measurements**|Nick von Selzam et.al.|[2407.04673v1](http://arxiv.org/abs/2407.04673v1)|null|Measurement correlations in quantum systems can exhibit non-local behavior, a fundamental aspect of quantum mechanics with applications such as device-independent quantum information processing. However, the explicit construction of local hidden-variable (LHV) models remains an outstanding challenge in the general setting. To address this, we develop an approach that employs gradient-descent algorithms from machine learning to find LHV models which reproduce the statistics of arbitrary measurements for quantum many-body states. In contrast to previous approaches, our method employs a general ansatz, enabling it to discover an LHV model in all cases where the state is local. Therefore, it provides actual estimates for the critical noise levels at which two-qubit Werner states and three-qubit GHZ and W states become non-local. Furthermore, we find evidence suggesting that two-spin subsystems in the ground states of translationally invariant Hamiltonians are local, while bigger subsystems are in general not. Our method now offers a quantitative tool for determining the regimes of non-locality in any given physical context, including scenarios involving non-equilibrium and decoherence.|
|**2024-07-05**|**SmoQyDEAC.jl: A differential evolution package for the analytic continuation of imaginary time correlation functions**|James Neuhaus et.al.|[2407.04568v1](http://arxiv.org/abs/2407.04568v1)|null|We introduce the SmoQyDEAC.jl package, a Julia implementation of the Differential Evolution Analytic Continuation (DEAC) algorithm [N. S. Nichols et al., Phys. Rev. E 106, 025312 (2022)] for analytically continuing noisy imaginary time correlation functions to the real frequency axis. Our implementation supports fermionic and bosonic correlation functions on either the imaginary time or Matsubara frequency axes, and treatment of the covariance error in the input data. This paper presents an overview of the DEAC algorithm and the features implemented in the SmoQyDEAC.jl. It also provides detailed benchmarks of the package's output against the popular maximum entropy and stochastic analytic continuation methods. The code for this package can be downloaded from our GitHub repository at https://github.com/SmoQySuite/SmoQyDEAC.jl or installed using the Julia package manager. The online documentation, including examples, can be accessed at https://smoqysuite.github.io/SmoQyDEAC.jl/stable/.|
|**2024-07-05**|**Benchmarking structure-based three-dimensional molecular generative models using GenBench3D: ligand conformation quality matters**|Benoit Baillif et.al.|[2407.04424v1](http://arxiv.org/abs/2407.04424v1)|null|Three-dimensional (3D) deep molecular generative models offer the advantage of goal-directed generation based on 3D-dependent properties, such as binding affinity for structure-based design within binding pockets. Traditional benchmarks created to evaluate SMILES or molecular graphs generators, such as GuacaMol or MOSES, are limited to evaluate 3D generators as they do not assess the quality of the generated molecular conformation. In this work, we hence developed GenBench3D, which implements a new benchmark for models producing molecules within a binding pocket. Our main contribution is the Validity3D metric, evaluating the conformation quality using the likelihood of bond lengths and valence angles based on reference values observed in the Cambridge Structural Database. The LiGAN, 3D-SBDD, Pocket2Mol, TargetDiff, DiffSBDD and ResGen models were benchmarked. We show that only between 0% and 11% of generated molecules have valid conformations. Performing local relaxation of generated molecules in the pocket considerably improved the Validity3D for all models by a minimum increase of 40%. For LiGAN, 3D-SBDD, or TargetDiff, the set of valid relaxed molecules shows on average higher Vina score (i.e. worse) than the set of raw generated molecules, indicating that the binding affinity of raw generated molecules might be overestimated. Using the other scoring functions, that give higher importance to ligand strain, only yield improved scores when using valid relaxed molecules. Using valid relaxed molecules, TargetDiff and Pocket2Mol show better median Vina, Glide and Gold PLP scores than other models. We have publicly released GenBench3D on GitHub for broader use: https://github.com/bbaillif/genbench3d|
|**2024-07-05**|**Drop it All or Pick it Up? How Developers Responded to the Log4JShell Vulnerability**|Vittunyuta Maeprasart et.al.|[2407.04263v1](http://arxiv.org/abs/2407.04263v1)|null|Although using third-party libraries has become prevalent in contemporary software development, developers often struggle to update their dependencies. Prior works acknowledge that due to the migration effort, priority and other issues cause lags in the migration process. The common assumption is that developers should drop all other activities and prioritize fixing the vulnerability. Our objective is to understand developer behavior when facing high-risk vulnerabilities in their code. We explore the prolific, and possibly one of the cases of the Log4JShell, a vulnerability that has the highest severity rating ever, which received widespread media attention. Using a mixed-method approach, we analyze 219 GitHub Pull Requests (PR) and 354 issues belonging to 53 Maven projects affected by the Log4JShell vulnerability. Our study confirms that developers show a quick response taking from 5 to 6 days. However, instead of dropping everything, surprisingly developer activities tend to increase for all pending issues and PRs. Developer discussions involved either giving information (29.3\%) and seeking information (20.6\%), which is missing in existing support tools. Leveraging this possibly-one of a kind event, insights opens up a new line of research, causing us to rethink best practices and what developers need in order to efficiently fix vulnerabilities.|
|**2024-07-05**|**Simulating carbon mineralization at pore scale in capillary networks of digital rock**|David A. Lazo Vasquez et.al.|[2407.04238v1](http://arxiv.org/abs/2407.04238v1)|null|Predicting the geometrical evolution of the pore space in geological formations due to fluid-solid interactions has applications in reservoir engineering, oil recovery, and geological storage of carbon dioxide. However, modeling frameworks that combine fluid flow with physical and chemical processes at a rock's pore scale are scarce. Here, we report a method for modeling a rock's pore space as a network of connected capillaries and to simulate the capillary diameter modifications caused by reactive flow processes. Specifically, we model mineral erosion, deposition, dissolution, and precipitation processes by solving the transport equations iteratively, computing diameter changes within each capillary of the network simultaneously. Our automated modeling framework enables simulations on digital rock samples as large as (1.125mm)$^3$ with 125$\times 10^6$ voxels within seconds of CPU time per iteration. As an application of the computational method, we have simulated brine injection and calcium carbonate precipitation in sandstone. For quantitatively comparing simulation results obtained with models predicting either a constant or a flow-rate dependent precipitation, we track the time-dependent capillary diameter distribution as well as the permeability of the connected pore space. For validation and reuse, we have made the automated simulation workflow, the reactive flow model library, and the digital rock samples available in public repositories.|
|**2024-07-05**|**Efficient GANs for Document Image Binarization Based on DWT and Normalization**|Rui-Yang Ju et.al.|[2407.04231v1](http://arxiv.org/abs/2407.04231v1)|[link](https://github.com/ruiyangju/efficient_document_image_binarization)|For document image binarization task, generative adversarial networks (GANs) can generate images where shadows and noise are effectively removed, which allow for text information extraction. The current state-of-the-art (SOTA) method proposes a three-stage network architecture that utilizes six GANs. Despite its excellent model performance, the SOTA network architecture requires long training and inference times. To overcome this problem, this work introduces an efficient GAN method based on the three-stage network architecture that incorporates the Discrete Wavelet Transformation and normalization to reduce the input image size, which in turns, decrease both training and inference times. In addition, this work presents novel generators, discriminators, and loss functions to improve the model's performance. Experimental results show that the proposed method reduces the training time by 10% and the inference time by 26% when compared to the SOTA method while maintaining the model performance at 73.79 of Avg-Score. Our implementation code is available on GitHub at https://github.com/RuiyangJu/Efficient_Document_Image_Binarization.|
|**2024-07-05**|**Computer Vision for Clinical Gait Analysis: A Gait Abnormality Video Dataset**|Rahm Ranjan et.al.|[2407.04190v1](http://arxiv.org/abs/2407.04190v1)|null|Clinical gait analysis (CGA) using computer vision is an emerging field in artificial intelligence that faces barriers of accessible, real-world data, and clear task objectives. This paper lays the foundation for current developments in CGA as well as vision-based methods and datasets suitable for gait analysis. We introduce The Gait Abnormality in Video Dataset (GAVD) in response to our review of over 150 current gait-related computer vision datasets, which highlighted the need for a large and accessible gait dataset clinically annotated for CGA. GAVD stands out as the largest video gait dataset, comprising 1874 sequences of normal, abnormal and pathological gaits. Additionally, GAVD includes clinically annotated RGB data sourced from publicly available content on online platforms. It also encompasses over 400 subjects who have undergone clinical grade visual screening to represent a diverse range of abnormal gait patterns, captured in various settings, including hospital clinics and urban uncontrolled outdoor environments. We demonstrate the validity of the dataset and utility of action recognition models for CGA using pretrained models Temporal Segment Networks(TSN) and SlowFast network to achieve video abnormality detection of 94% and 92% respectively when tested on GAVD dataset. A GitHub repository https://github.com/Rahmyyy/GAVD consisting of convenient URL links, and clinically relevant annotation for CGA is provided for over 450 online videos, featuring diverse subjects performing a range of normal, pathological, and abnormal gait patterns.|
|**2024-07-04**|**From First Patch to Long-Term Contributor: Evaluating Onboarding Recommendations for OSS Newcomers**|Asif Kamal Turzo et.al.|[2407.04159v1](http://arxiv.org/abs/2407.04159v1)|null|Attracting and retaining a steady stream of new contributors is crucial to ensuring the long-term survival of open-source software (OSS) projects. However, there are two key research gaps regarding recommendations for onboarding new contributors to OSS projects. First, most of the existing recommendations are based on a limited number of projects, which raises concerns about their generalizability. If a recommendation yields conflicting results in a different context, it could hinder a newcomer's onboarding process rather than help them. Second, it's unclear whether these recommendations also apply to experienced contributors. If certain recommendations are specific to newcomers, continuing to follow them after their initial contributions are accepted could hinder their chances of becoming long-term contributors. To address these gaps, we conducted a two-stage mixed-method study. In the first stage, we conducted a Systematic Literature Review (SLR) and identified 15 task-related actionable recommendations that newcomers to OSS projects can follow to improve their odds of successful onboarding. In the second stage, we conduct a large-scale empirical study of five Gerrit-based projects and 1,155 OSS projects from GitHub to assess whether those recommendations assist newcomers' successful onboarding. Our results suggest that four recommendations positively correlate with newcomers' first patch acceptance in most contexts. Four recommendations are context-dependent, and four indicate significant negative associations for most projects. Our results also found three newcomer-specific recommendations, which OSS joiners should abandon at non-newcomer status to increase their odds of becoming long-term contributors.|
|**2024-07-04**|**FunAudioLLM: Voice Understanding and Generation Foundation Models for Natural Interaction Between Humans and LLMs**|Tongyi SpeechTeam et.al.|[2407.04051v1](http://arxiv.org/abs/2407.04051v1)|null|This report introduces FunAudioLLM, a model family designed to enhance natural voice interactions between humans and large language models (LLMs). At its core are two innovative models: SenseVoice, which handles multilingual speech recognition, emotion recognition, and audio event detection; and CosyVoice, which facilitates natural speech generation with control over multiple languages, timbre, speaking style, and speaker identity. SenseVoice-Small delivers exceptionally low-latency ASR for 5 languages, and SenseVoice-Large supports high-precision ASR for over 50 languages, while CosyVoice excels in multi-lingual voice generation, zero-shot in-context learning, cross-lingual voice cloning, and instruction-following capabilities. The models related to SenseVoice and CosyVoice have been open-sourced on Modelscope and Huggingface, along with the corresponding training, inference, and fine-tuning codes released on GitHub. By integrating these models with LLMs, FunAudioLLM enables applications such as speech-to-speech translation, emotional voice chat, interactive podcasts, and expressive audiobook narration, thereby pushing the boundaries of voice interaction technology. Demos are available at https://fun-audio-llm.github.io, and the code can be accessed at https://github.com/FunAudioLLM.|
|**2024-07-03**|**Visualizing the Evolution of Twitter (X.com) Conversations: A Comprehensive Methodology Applied to AI Training Discussions on ChatGPT**|Nicole Jess et.al.|[2407.03484v1](http://arxiv.org/abs/2407.03484v1)|null|With the rise of social media platforms, especially X.com (formerly Twitter), there is a growing interest in understanding digital social networks and human digital interactions. This paper presents a comprehensive methodology for extracting, processing, and visually analyzing data from X.com, using a combination of Python and R packages, enhanced by our publicly accessible, customizable code. Our approach compiles a dynamic dataset that captures various interactions: replies, retweets, and mentions. To explore deeper insights, the data is subjected to sentiment analysis and keyword coding, indicating shifts in discourse over time. Our method is structured in three primary phases. Initially, R is employed for pulling data and the formation of social network datasets. Following this, the combination of Python and R is utilized for sentiment analysis and keyword coding, aiming to uncover the underlying emotional shifts and language transitions within topics of discussion. The final phase employs R to visualize the dynamic shifts within these social networks. These visualization tools highlight changes in user interactions and patterns of influence. For a practical demonstration, we analyzed conversations on X.com regarding the controversial proposal to halt AI development, focusing specifically on discussions about ChatGPT. By using keyword searches, leading voices in the debate were identified. Our analysis of sentiment and keywords revealed patterns in emotions and language, while visual tools illustrated the development of network connections and their influence. This study emphasizes the vital role of visual tools in understanding online social dynamics in the digital age.|
|**2024-07-03**|**MotifbreakR v2: extended capability and database integration**|Simon G. Coetzee et.al.|[2407.03441v1](http://arxiv.org/abs/2407.03441v1)|null|MotifbreakR is a software tool that scans genetic variants against position weight matrices of transcription factors (TF) to determine the potential for the disruption of TF binding at the site of the variant. It leverages the Bioconductor suite of software packages and annotations to operate across a diverse array of genomes and motif databases. Initially developed to interrogate the effect of single nucleotide variants (common and rare SNVs) on potential TF binding sites, in motifbreakR v2, we have updated the functionality. New features include the ability to query other types of more complex genetic variants, such as short insertions and deletions (indels). This function allows modeling a more extensive array of variants that may have more significant effects on TF binding. Additionally, while TF binding is based partly on sequence preference, predictions of TF binding based on sequence preference alone can indicate many more potential binding events than observed. Adding information from DNA-binding sequencing datasets lends confidence to motif disruption prediction by demonstrating TF binding in cell lines and tissue types. Therefore, motifbreakR implements querying the ReMap2022 database for evidence that a TF matching the disrupted motif binds over the disrupting variant. Finally, in motifbreakR, in addition to the existing interface, we have implemented an R/Shiny graphical user interface to simplify and enhance access to researchers with different skill sets.|
|**2024-07-03**|**Global Context Modeling in YOLOv8 for Pediatric Wrist Fracture Detection**|Rui-Yang Ju et.al.|[2407.03163v1](http://arxiv.org/abs/2407.03163v1)|[link](https://github.com/ruiyangju/yolov8_global_context_fracture_detection)|Children often suffer wrist injuries in daily life, while fracture injuring radiologists usually need to analyze and interpret X-ray images before surgical treatment by surgeons. The development of deep learning has enabled neural network models to work as computer-assisted diagnosis (CAD) tools to help doctors and experts in diagnosis. Since the YOLOv8 models have obtained the satisfactory success in object detection tasks, it has been applied to fracture detection. The Global Context (GC) block effectively models the global context in a lightweight way, and incorporating it into YOLOv8 can greatly improve the model performance. This paper proposes the YOLOv8+GC model for fracture detection, which is an improved version of the YOLOv8 model with the GC block. Experimental results demonstrate that compared to the original YOLOv8 model, the proposed YOLOv8-GC model increases the mean average precision calculated at intersection over union threshold of 0.5 (mAP 50) from 63.58% to 66.32% on the GRAZPEDWRI-DX dataset, achieving the state-of-the-art (SOTA) level. The implementation code for this work is available on GitHub at https://github.com/RuiyangJu/YOLOv8_Global_Context_Fracture_Detection.|
|**2024-07-03**|**Self-supervised Vision Transformer are Scalable Generative Models for Domain Generalization**|Sebastian Doerrich et.al.|[2407.02900v1](http://arxiv.org/abs/2407.02900v1)|[link](https://github.com/sdoerrich97/vits-are-generative-models)|Despite notable advancements, the integration of deep learning (DL) techniques into impactful clinical applications, particularly in the realm of digital histopathology, has been hindered by challenges associated with achieving robust generalization across diverse imaging domains and characteristics. Traditional mitigation strategies in this field such as data augmentation and stain color normalization have proven insufficient in addressing this limitation, necessitating the exploration of alternative methodologies. To this end, we propose a novel generative method for domain generalization in histopathology images. Our method employs a generative, self-supervised Vision Transformer to dynamically extract characteristics of image patches and seamlessly infuse them into the original images, thereby creating novel, synthetic images with diverse attributes. By enriching the dataset with such synthesized images, we aim to enhance its holistic nature, facilitating improved generalization of DL models to unseen domains. Extensive experiments conducted on two distinct histopathology datasets demonstrate the effectiveness of our proposed approach, outperforming the state of the art substantially, on the Camelyon17-wilds challenge dataset (+2%) and on a second epithelium-stroma dataset (+26%). Furthermore, we emphasize our method's ability to readily scale with increasingly available unlabeled data samples and more complex, higher parametric architectures. Source code is available at https://github.com/sdoerrich97/vits-are-generative-models .|
|**2024-07-02**|**Output Range Analysis for Deep Neural Networks based on Simulated Annealing Processes**|Helder Rojas et.al.|[2407.02700v1](http://arxiv.org/abs/2407.02700v1)|[link](https://github.com/nicerova7/output-range-analysis-for-deep-neural-networks-with-simulated-annealing)|This paper tackles the challenging problem of output range estimation for Deep Neural Networks (DNNs), introducing a novel algorithm based on Simulated Annealing (SA). Our approach addresses the lack of local geometric information and high non-linearity in DNNs, making it versatile across various architectures, especially Residual Neural Networks (ResNets). We present a straightforward, implementation-friendly algorithm that avoids restrictive assumptions about network architecture. Through theoretical analysis and experimental evaluations, including tests on the Ackley function, we demonstrate our algorithm's effectiveness in navigating complex, non-convex surfaces and accurately estimating DNN output ranges. Futhermore, the Python codes of this experimental evaluation that support our results are available in our GitHub repository (https://github.com/Nicerova7/output-range-analysis-for-deep-neural-networks-with-simulated-annealing).|
|**2024-07-02**|**A Novel Approach to Image EEG Sleep Data for Improving Quality of Life in Patients Suffering From Brain Injuries Using DreamDiffusion**|David Fahim et.al.|[2407.02673v1](http://arxiv.org/abs/2407.02673v1)|null|Those experiencing strokes, traumatic brain injuries, and drug complications can often end up hospitalized and diagnosed with coma or locked-in syndrome. Such mental impediments can permanently alter the neurological pathways in work and significantly decrease the quality of life (QoL). It is critical to translate brain signals into images to gain a deeper understanding of the thoughts of a comatose patient. Traditionally, brain signals collected by an EEG could only be translated into text, but with the novel method of an open-source model available on GitHub, DreamDiffusion can be used to convert brain waves into images directly. DreamDiffusion works by extracting features from EEG signals and then using the features to create images through StableDiffusion. Upon this, we made further improvements that could make StableDiffusion the forerunner technology in waves to media translation. In our study, we begin by modifying the existing DreamDiffusion codebase so that it does not require any prior setup, avoiding any confusing steps needed to run the model from GitHub. For many researchers, the incomplete setup process, errors in the existing code, and a lack of directions made it nearly impossible to run, not even considering the model's performance. We brought the code into Google Colab so users could run and evaluate problems cell-by-cell, eliminating the specific file and repository dependencies. We also provided the original training data file so users do not need to purchase the necessary computing power to train the model from the given dataset. The second change is utilizing the mutability of the code and optimizing the model so it can be used to generate images from other given inputs, such as sleep data. Additionally, the affordability of EEG technology allows for global dissemination and creates the opportunity for those who want to work on the shared DreamDiffusion model.|
|**2024-07-02**|**Ensuring Responsible Sourcing of Large Language Model Training Data Through Knowledge Graph Comparison**|Devam Mondal et.al.|[2407.02659v1](http://arxiv.org/abs/2407.02659v1)|null|In light of recent plagiarism allegations Brough by publishers, newspapers, and other creators of copyrighted corpora against large language model (LLM) developers, we propose a novel system, a variant of a plagiarism detection system, that assesses whether a knowledge source has been used in the training or fine-tuning of a large language model. Unlike current methods, we utilize an approach that uses Resource Description Framework (RDF) triples to create knowledge graphs from both a source document and a LLM continuation of that document. These graphs are then analyzed with respect to content using cosine similarity and with respect to structure using a normalized version of graph edit distance that shows the degree of isomorphism. Unlike traditional systems that focus on content matching and keyword identification between a source and target corpus, our approach enables a broader evaluation of similarity and thus a more accurate comparison of the similarity between a source document and LLM continuation by focusing on relationships between ideas and their organization with regards to others. Additionally, our approach does not require access to LLM metrics like perplexity that may be unavailable in closed large language modeling "black-box" systems, as well as the training corpus. A prototype of our system will be found on a hyperlinked GitHub repository.|
|**2024-07-02**|**Example-Based Automatic Migration of Continuous Integration Systems**|Dhia Elhaq Rzig et.al.|[2407.02644v1](http://arxiv.org/abs/2407.02644v1)|null|Continuous Integration (CI) is a widely adopted practice for faster code change integration and testing. Developers often migrate between CI systems in pursuit of features like matrix building or better logging. However, this migration is effort intensive and error-prone owing to limited knowledge of the new CI system and its syntax. Moreover, these migrations require multiple iterations and significant time to achieve stability in the new CI system, and there is insufficient support for the automatic migration of CI configurations.   To mitigate this, we propose a novel approach for CI system's automatic migration: CIMig. Our approach utilizes Example-Based mining, where it extracts translation rules and configuration patterns from existing migration examples, and employs them to reproduce this migration in new contexts. To empirically validate and evaluate our approach, we apply it to the migration between Travis CI and GitHub Actions. We gathered learnings from 1001 projects, and then applied them to migrate an evaluation set of 251 projects. This helped us perform a qualitative and quantitative evaluation of CIMig, and we contextualize our results by comparing them with those of the manual-rule-based GitHub Actions Importer. Furthermore, our tool generated files that were rated favorably by developers and saved them an average of 42.4 minutes over the manual migration of these same projects. Our learning-based approach is also more flexible, as proven by our ability to apply it to migrate GitHub Actions files to Travis, which GitHub Actions Importer can not do. We believe CIMig is the first approach of its kin to migrate CI systems and can be applied to other software configuration system migrations. Our replication package is available at [5].|
|**2024-07-02**|**Is Your AI-Generated Code Really Safe? Evaluating Large Language Models on Secure Code Generation with CodeSecEval**|Jiexin Wang et.al.|[2407.02395v2](http://arxiv.org/abs/2407.02395v2)|null|Large language models (LLMs) have brought significant advancements to code generation and code repair, benefiting both novice and experienced developers. However, their training using unsanitized data from open-source repositories, like GitHub, raises the risk of inadvertently propagating security vulnerabilities. Despite numerous studies investigating the safety of code LLMs, there remains a gap in comprehensively addressing their security features. In this work, we aim to present a comprehensive study aimed at precisely evaluating and enhancing the security aspects of code LLMs. To support our research, we introduce CodeSecEval, a meticulously curated dataset designed to address 44 critical vulnerability types with 180 distinct samples. CodeSecEval serves as the foundation for the automatic evaluation of code models in two crucial tasks: code generation and code repair, with a strong emphasis on security. Our experimental results reveal that current models frequently overlook security issues during both code generation and repair processes, resulting in the creation of vulnerable code. In response, we propose different strategies that leverage vulnerability-aware information and insecure code explanations to mitigate these security vulnerabilities. Furthermore, our findings highlight that certain vulnerability types particularly challenge model performance, influencing their effectiveness in real-world applications. Based on these findings, we believe our study will have a positive impact on the software engineering community, inspiring the development of improved methods for training and utilizing LLMs, thereby leading to safer and more trustworthy model deployment.|
|**2024-07-02**|**The coherent magnetic halo of Milky Way**|A. Korochkin et.al.|[2407.02148v1](http://arxiv.org/abs/2407.02148v1)|null|Recent catalog of Faraday rotation measures (RM) of extragalactic sources together with the synchrotron polarization data from WMAP and Planck provide us with the wealth of information on magnetic fields of the Galaxy. However, the integral character of these observables together with our position inside the Galaxy makes the inference of the coherent Galactic magnetic field (GMF) complicated and ambiguous. We combine several phenomenological components of the GMF -- the spiral arms, the toroidal halo, the X-shaped field and the field of the Local Bubble -- to construct a new model of the regular GMF outside of the thin disk. To have control over the relative contributions of the RM and polarization data to the fit we pay special attention to the estimation of errors in data bins. To this end we develop a systematic method which is uniformly applicable to different data sets. This method takes into account individual measurement errors, the variance in the bin as well as fluctuations in the data at angular scales larger than the bin size. This leads to decrease of the errors and, as a result, to better sensitivity of the data to the model content. We cross checked the stability of our method with the new LOFAR data. We found that the four components listed above are sufficient to fit both the RM and polarization data over the whole sky with only a small fraction masked out. Moreover, we have achieved several important improvements compared to previous approaches. Due to account of our location inside of the Local Bubble our model does not require introduction of striated fields. For the first time we showed that the Fan Region can be modeled as a Galactic-scale feature. The pitch angle of the magnetic field in our fit converged to the value around 20 degrees. Interestingly, with value is very close to the direction of arms inferred recently from Gaia data on upper main sequence stars.|
|**2024-07-02**|**Fake News Detection: It's All in the Data!**|Soveatin Kuntur et.al.|[2407.02122v1](http://arxiv.org/abs/2407.02122v1)|[link](https://github.com/KaiDMML/FakeNewsNet)|This comprehensive survey serves as an indispensable resource for researchers embarking on the journey of fake news detection. By highlighting the pivotal role of dataset quality and diversity, it underscores the significance of these elements in the effectiveness and robustness of detection models. The survey meticulously outlines the key features of datasets, various labeling systems employed, and prevalent biases that can impact model performance. Additionally, it addresses critical ethical issues and best practices, offering a thorough overview of the current state of available datasets. Our contribution to this field is further enriched by the provision of GitHub repository, which consolidates publicly accessible datasets into a single, user-friendly portal. This repository is designed to facilitate and stimulate further research and development efforts aimed at combating the pervasive issue of fake news.|
|**2024-07-02**|**A Fast Multitaper Power Spectrum Estimation in Nonuniformly Sampled Time Series**|Jie Cui et.al.|[2407.01943v2](http://arxiv.org/abs/2407.01943v2)|null|Nonuniformly sampled signals are prevalent in real-world applications but pose a significant challenge when estimating their power spectra from a finite number of samples of a single realization. The optimal solution using Bronez Generalized Prolate Spheroidal Sequence (GPSS) is computationally intensive and thus impractical for large datasets. This paper presents a fast nonparametric method, MultiTaper NonUniform Fast Fourier Transform (MTNUFFT), capable of estimating power spectra with lower computational burden. The method first derives a set of optimal tapers via cubic spline interpolation on a nominal analysis band, and subsequently shifts these tapers to other analysis bands using NonUniform FFT (NUFFT). The estimated spectral power within the band is the average power at the outputs of the taper set. This algorithm eliminates the time-consuming computation for solving the Generalized Eigenvalue Problem (GEP), thus reducing the computational load from $O(N^4)$ to $O(N \log N + N \log(1/\epsilon))$, comparable with the NUFFT. The statistical properties of the estimator are assessed using Bronez GPSS theory, revealing that the bias and variance bound of the MTNUFFT estimator are identical to those of the optimal estimator. Furthermore, the degradation of bias bound can serve as a measure of the deviation from optimality. The performance of the estimator is evaluated using both simulation and real-world data, demonstrating its practical applicability. The code of the proposed fast algorithm is available on GitHub (https://github.com/jiecui/mtnufft).|
|**2024-07-01**|**LEXI: Large Language Models Experimentation Interface**|Guy Laban et.al.|[2407.01488v2](http://arxiv.org/abs/2407.01488v2)|null|The recent developments in Large Language Models (LLM), mark a significant moment in the research and development of social interactions with artificial agents. These agents are widely deployed in a variety of settings, with potential impact on users. However, the study of social interactions with agents powered by LLM is still emerging, limited by access to the technology and to data, the absence of standardised interfaces, and challenges to establishing controlled experimental setups using the currently available business-oriented platforms. To answer these gaps, we developed LEXI, LLMs Experimentation Interface, an open-source tool enabling the deployment of artificial agents powered by LLM in social interaction behavioural experiments. Using a graphical interface, LEXI allows researchers to build agents, and deploy them in experimental setups along with forms and questionnaires while collecting interaction logs and self-reported data. The outcomes of usability testing indicate LEXI's broad utility, high usability and minimum mental workload requirement, with distinctive benefits observed across disciplines. A proof-of-concept study exploring the tool's efficacy in evaluating social HAIs was conducted, resulting in high-quality data. A comparison of empathetic versus neutral agents indicated that people perceive empathetic agents as more social, and write longer and more positive messages towards them.|
|**2024-07-01**|**Kolmogorov-Arnold Convolutions: Design Principles and Empirical Studies**|Ivan Drokin et.al.|[2407.01092v1](http://arxiv.org/abs/2407.01092v1)|[link](https://github.com/ivandrokin/torch-conv-kan)|The emergence of Kolmogorov-Arnold Networks (KANs) has sparked significant interest and debate within the scientific community. This paper explores the application of KANs in the domain of computer vision (CV). We examine the convolutional version of KANs, considering various nonlinearity options beyond splines, such as Wavelet transforms and a range of polynomials. We propose a parameter-efficient design for Kolmogorov-Arnold convolutional layers and a parameter-efficient finetuning algorithm for pre-trained KAN models, as well as KAN convolutional versions of self-attention and focal modulation layers. We provide empirical evaluations conducted on MNIST, CIFAR10, CIFAR100, Tiny ImageNet, ImageNet1k, and HAM10000 datasets for image classification tasks. Additionally, we explore segmentation tasks, proposing U-Net-like architectures with KAN convolutions, and achieving state-of-the-art results on BUSI, GlaS, and CVC datasets. We summarized all of our findings in a preliminary design guide of KAN convolutional models for computer vision tasks. Furthermore, we investigate regularization techniques for KANs. All experimental code and implementations of convolutional layers and models, pre-trained on ImageNet1k weights are available on GitHub via this https://github.com/IvanDrokin/torch-conv-kan|
|**2024-06-30**|**Diffusion Models and Representation Learning: A Survey**|Michael Fuest et.al.|[2407.00783v1](http://arxiv.org/abs/2407.00783v1)|[link](https://github.com/dongzhuoyao/diffusion-representation-learning-survey-taxonomy)|Diffusion Models are popular generative modeling methods in various vision tasks, attracting significant attention. They can be considered a unique instance of self-supervised learning methods due to their independence from label annotation. This survey explores the interplay between diffusion models and representation learning. It provides an overview of diffusion models' essential aspects, including mathematical foundations, popular denoising network architectures, and guidance methods. Various approaches related to diffusion models and representation learning are detailed. These include frameworks that leverage representations learned from pre-trained diffusion models for subsequent recognition tasks and methods that utilize advancements in representation and self-supervised learning to enhance diffusion models. This survey aims to offer a comprehensive overview of the taxonomy between diffusion models and representation learning, identifying key areas of existing concerns and potential exploration. Github link: https://github.com/dongzhuoyao/Diffusion-Representation-Learning-Survey-Taxonomy|
|**2024-06-28**|**EPOCH: Jointly Estimating the 3D Pose of Cameras and Humans**|Nicola Garau et.al.|[2406.19726v1](http://arxiv.org/abs/2406.19726v1)|null|Monocular Human Pose Estimation (HPE) aims at determining the 3D positions of human joints from a single 2D image captured by a camera. However, a single 2D point in the image may correspond to multiple points in 3D space. Typically, the uniqueness of the 2D-3D relationship is approximated using an orthographic or weak-perspective camera model. In this study, instead of relying on approximations, we advocate for utilizing the full perspective camera model. This involves estimating camera parameters and establishing a precise, unambiguous 2D-3D relationship. To do so, we introduce the EPOCH framework, comprising two main components: the pose lifter network (LiftNet) and the pose regressor network (RegNet). LiftNet utilizes the full perspective camera model to precisely estimate the 3D pose in an unsupervised manner. It takes a 2D pose and camera parameters as inputs and produces the corresponding 3D pose estimation. These inputs are obtained from RegNet, which starts from a single image and provides estimates for the 2D pose and camera parameters. RegNet utilizes only 2D pose data as weak supervision. Internally, RegNet predicts a 3D pose, which is then projected to 2D using the estimated camera parameters. This process enables RegNet to establish the unambiguous 2D-3D relationship. Our experiments show that modeling the lifting as an unsupervised task with a camera in-the-loop results in better generalization to unseen data. We obtain state-of-the-art results for the 3D HPE on the Human3.6M and MPI-INF-3DHP datasets. Our code is available at: [Github link upon acceptance, see supplementary materials].|
|**2024-06-28**|**Efficient Tensor Network Algorithms for Spin Foam Models**|Seth K. Asante et.al.|[2406.19676v1](http://arxiv.org/abs/2406.19676v1)|null|Numerical computations and methods have become increasingly crucial in the study of spin foam models across various regimes. This paper adds to this field by introducing new algorithms based on tensor network methods for computing amplitudes, focusing on topological SU(2) BF and Lorentzian EPRL spin foam models. By reorganizing the sums and tensors involved, vertex amplitudes are recast as a sequence of matrix contractions. This reorganization significantly reduces computational complexity and memory usage, allowing for scalable and efficient computations of the amplitudes for larger representation labels on standard consumer hardware--previously infeasible due to the computational demands of high-valent tensors.   We apply these tensor network algorithms to analyze the characteristics of various vertex configurations, including Regge and vector geometries for the SU(2) BF theory, demonstrating consistent scaling behavior and differing oscillation patterns. Our benchmarks reveal substantial improvements in computational time and memory allocations, especially for large representation labels. Additionally, these tensor network methods are applicable to generic 2-complexes with multiple vertices, where we introduce partial-coherent vertex amplitudes to streamline the computations. The implementation of these algorithms is available on GitHub for further exploration and use.|
|**2024-06-28**|**A Survey on Data Quality Dimensions and Tools for Machine Learning**|Yuhan Zhou et.al.|[2406.19614v1](http://arxiv.org/abs/2406.19614v1)|null|Machine learning (ML) technologies have become substantial in practically all aspects of our society, and data quality (DQ) is critical for the performance, fairness, robustness, safety, and scalability of ML models. With the large and complex data in data-centric AI, traditional methods like exploratory data analysis (EDA) and cross-validation (CV) face challenges, highlighting the importance of mastering DQ tools. In this survey, we review 17 DQ evaluation and improvement tools in the last 5 years. By introducing the DQ dimensions, metrics, and main functions embedded in these tools, we compare their strengths and limitations and propose a roadmap for developing open-source DQ tools for ML. Based on the discussions on the challenges and emerging trends, we further highlight the potential applications of large language models (LLMs) and generative AI in DQ evaluation and improvement for ML. We believe this comprehensive survey can enhance understanding of DQ in ML and could drive progress in data-centric AI. A complete list of the literature investigated in this survey is available on GitHub at: https://github.com/haihua0913/awesome-dq4ml.|
|**2024-06-27**|**Where Are Large Language Models for Code Generation on GitHub?**|Xiao Yu et.al.|[2406.19544v1](http://arxiv.org/abs/2406.19544v1)|null|The increasing use of Large Language Models (LLMs) in software development has garnered significant attention from researchers assessing the quality of the code they generate. However, much of the research focuses on controlled datasets such as HumanEval, which fail to adequately represent how developers actually utilize LLMs' code generation capabilities or clarify the characteristics of LLM-generated code in real-world development scenarios. To bridge this gap, our study investigates the characteristics of LLM-generated code and its corresponding projects hosted on GitHub. Our findings reveal several key insights: (1) ChatGPT and Copilot are the most frequently utilized for generating code on GitHub. In contrast, there is very little code generated by other LLMs on GitHub. (2) Projects containing ChatGPT/Copilot-generated code are often small and less known, led by individuals or small teams. Despite this, most projects are continuously evolving and improving. (3) ChatGPT/Copilot is mainly utilized for generating Python, Java, and TypeScript scripts for data processing and transformation. C/C++ and JavaScript code generation focuses on algorithm and data structure implementation and user interface code. Most ChatGPT/Copilot-generated code snippets are relatively short and exhibit low complexity. (4) Compared to human-written code, ChatGPT/Copilot-generated code exists in a small proportion of projects and generally undergoes fewer modifications. Additionally, modifications due to bugs are even fewer, ranging from just 3% to 8% across different languages. (5) Most comments on ChatGPT/Copilot-generated code lack detailed information, often only stating the code's origin without mentioning prompts, human modifications, or testing status. Based on these findings, we discuss the implications for researchers and practitioners.|
|**2024-06-27**|**Secure quantum-enhanced measurements on a network of sensors**|Sean William Moore et.al.|[2406.19285v1](http://arxiv.org/abs/2406.19285v1)|null|Two-party secure quantum remote sensing (SQRS) protocols enable quantum-enhanced measurements at remote locations with guaranteed security against eavesdroppers. This idea can be scaled up to networks of nodes where one party can directly measure functions of parameters at the different nodes using entangled states. However, the security on such networks decreases exponentially with the number of nodes. Here we show how this problem can be overcome in a hybrid protocol that utilises both entangled and separable states to achieve quantum-enhanced measurement precision and security on networks of any size.|
|**2024-06-27**|**Empirical Investigation of the Relationship Between Design Smells and Role Stereotypes**|Daniel Ogenrwot et.al.|[2406.19254v1](http://arxiv.org/abs/2406.19254v1)|null|During software development, poor design and implementation choices can detrimentally impact software maintainability. Design smells, recurring patterns of poorly designed fragments, signify these issues. Role-stereotypes denote the generic responsibilities that classes assume in system design. Although the concepts of role-stereotypes and design smells differ, both significantly contribute to the design and maintenance of software systems. Understanding the relationship between these aspects is crucial for enhancing software maintainability, code quality, efficient code review, guided refactoring, and the design of role-specific metrics. This paper employs an exploratory approach, combining statistical analysis and unsupervised learning methods, to understand how design smells relate to role-stereotypes across desktop and mobile applications. Analyzing 11,350 classes from 30 GitHub repositories, we identified several design smells that frequently co-occur within certain role-stereotypes. Specifically, three (3) out of six (6) role-stereotypes we studied are more prone to design smells. We also examined the variation of design smells across the two ecosystems, driven by notable differences in their underlying architecture. Findings revealed that design smells are more prevalent in desktop than in mobile applications, especially within the Service Provider and Information Holder role-stereotypes. Additionally, the unsupervised learning method showed that certain pairs or groups of role-stereotypes are prone to similar types of design smells. We believe these relationships are associated with the characteristic and collaborative properties between role-stereotypes. The insights from this research provide valuable guidance for software teams on implementing design smell prevention and correction mechanisms, ensuring conceptual integrity during design and maintenance phases.|
