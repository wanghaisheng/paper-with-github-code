---
layout: '../../layouts/MarkdownPost.astro'
title: 'Efficient Tensor Network Algorithms for Spin Foam Models'
pubDate: 2024-07-09 04:41:41
description: ''
author: 'wanghaisheng'
cover:
    url: 'https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg'
    square: 'https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg'
    alt: 'cover'
tags: ['all search terms'] 
theme: 'light'
featured: true

meta:
 - name: author
   content: Seth K. Asante et.al.
 - name: keywords
   content: key3, key4

keywords: key1, key2, key3
---

## paper id
2406.19676v1
## download
[2406.19676v1](http://arxiv.org/abs/2406.19676v1)
## abstracts:
Numerical computations and methods have become increasingly crucial in the study of spin foam models across various regimes. This paper adds to this field by introducing new algorithms based on tensor network methods for computing amplitudes, focusing on topological SU(2) BF and Lorentzian EPRL spin foam models. By reorganizing the sums and tensors involved, vertex amplitudes are recast as a sequence of matrix contractions. This reorganization significantly reduces computational complexity and memory usage, allowing for scalable and efficient computations of the amplitudes for larger representation labels on standard consumer hardware--previously infeasible due to the computational demands of high-valent tensors.   We apply these tensor network algorithms to analyze the characteristics of various vertex configurations, including Regge and vector geometries for the SU(2) BF theory, demonstrating consistent scaling behavior and differing oscillation patterns. Our benchmarks reveal substantial improvements in computational time and memory allocations, especially for large representation labels. Additionally, these tensor network methods are applicable to generic 2-complexes with multiple vertices, where we introduce partial-coherent vertex amplitudes to streamline the computations. The implementation of these algorithms is available on GitHub for further exploration and use.
## QA:
coming soon
